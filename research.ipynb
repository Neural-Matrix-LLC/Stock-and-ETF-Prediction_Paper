{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bd390b-21ca-4ae5-b3bb-4a31dc903eb9",
   "metadata": {},
   "source": [
    "# Stock Price Prediction\n",
    "\n",
    "**Keywords:** Stock price prediciton, Deep Learning, RNN, LSTM, Bi-LSTM, Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e108c21a-c35b-4ccd-b805-429c162702c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recurrent Neural Network (RNN)\n",
    "\n",
    "A recurrent neural network (RNN) is a type of artificial neural network where the computation graph contains directed cycles. \n",
    "\n",
    "Since a RNN's hidden layers have connections back to themselves (recurrent units), the states of the hidden layers at one time instant to be used as input to the hidden layers at the next time instant, enabling the algorithm to process sequence data. This allows hidden states to capture information about the temporal relation between input sequences and output sequences.\n",
    "\n",
    "In simplest terms, the following equations define how an RNN evolves over time:\n",
    "$$ o^t = f(h^t; \\theta) $$\n",
    "$$ h^t = g(h^{t-1}, x^t; \\theta) $$\n",
    "where where $o^t$ is the output of the RNN at time $t$, $x^t$ is the input to the RNN at time $t$, and $h^t$ is the state of the hidden layer(s) at time $t$.\n",
    "\n",
    "The image below outlines a simple graphical model to illustrate the relation between these three variables in an RNN's computation graph.\n",
    "\n",
    "<center><img src=\"img/rnn.png\" width=\"150px\"></center>\n",
    "\n",
    "*A graphical model for an RNN. The values $\\theta_i$, $\\theta_h$, and $\\theta_o$ represent the parameters associated with the inputs, previous hidden layer states, and outputs, respectively*\n",
    "\n",
    "The first equation says that, given parameters $\\theta$ (which encapsulates the weights and biases for the network), the output at time $t$ depends only on the state of the hidden layer at time $t$. \n",
    "\n",
    "The second equation says that, given the same parameters $\\theta$, the hidden layer at time $t$ depends on the hidden layer at time $t-1$ and the input at time $t$. This second equation demonstrates that the RNN can remember its past by allowing past computations $h^{t-1}$ to influence the present computations $h^{t}$.\n",
    "\n",
    "One issue with RNNs in general is known as the vanishing/exploding gradients problem. This problem states that, for long input-output sequences, RNNs have trouble modeling long-term dependencies, that is, the relationship between elements in the sequence that are separated by large periods of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d52f4-e2cf-4d2b-b96a-ab59d4fa9869",
   "metadata": {},
   "source": [
    "## Long Short-term Memory\n",
    "\n",
    "RNN variants such as Long Short-Term Memory (LSTM) have been able to overcome the vanishing/exploding gradient problem\n",
    "\n",
    "LSTM RNNs work by allowing the input $x_t$ at time $t$ to influence the storing or overwriting of \"memories\" stored in the cell. This decision is determined by two different functions, called the input gate for storing new memories, and the forget gate for forgetting old memories. A final output gate determines when to output the value stored in the memory cell to the hidden layer. \n",
    "\n",
    "The image below illustrates the computation graph for the memory portion of an LSTM RNN (i.e. it does not include the hidden layer or output layer).\n",
    "\n",
    "<center><img src=\"img/lstm.png\" width=\"350px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb11b32-abc4-4651-813a-07af63caa8a2",
   "metadata": {},
   "source": [
    "## Work Cited\n",
    "\n",
    "Patel, Janik, et al. \"Stock Price Prediction Using RNN and LSTM.\" *JETIR*, vol.5, no. 11, Nov 18. 2018. \n",
    "https://www.jetir.org/papers/JETIRK006164.pdf\n",
    "\n",
    "McGonagle, John, et al. \"Recurrent Neural Network.\" *Brilliant.org.* https://brilliant.org/wiki/recurrent-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b6f10-b34f-4691-bd2b-a144cbb47fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
